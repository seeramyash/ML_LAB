{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Logistic Regression on Iris (Colab-ready)\n",
        "\n",
        "A gentle, end-to-end notebook for **Logistic Regression** using the classic **Iris** dataset.\n",
        "\n",
        "We will:\n",
        "1. Load the data\n",
        "2. Explore and visualize\n",
        "3. Split into train/test\n",
        "4. Train Logistic Regression\n",
        "5. Evaluate with accuracy, confusion matrix, classification report\n",
        "6. Try a few test-time predictions\n",
        "\n",
        "**Tip:** Run cells from top to bottom. If you get a warning about convergence, we set a higher `max_iter` later.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 0) Setup: install/upgrade packages if needed (Colab usually has these)\n",
        "import sys\n",
        "print(sys.version)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Load the Iris dataset\n",
        "We'll use `sklearn.datasets.load_iris`. It returns features `data`, labels `target`, and metadata like feature names and target names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iris = load_iris()\n",
        "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y = pd.Series(iris.target, name='target')\n",
        "target_names = iris.target_names\n",
        "feature_names = iris.feature_names\n",
        "print(f\"Shape X: {X.shape}, y: {y.shape}\")\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Quick EDA & Visualization\n",
        "- Peek at basic statistics\n",
        "- Plot histograms\n",
        "- A simple scatter plot (petal length vs petal width)\n",
        "\n",
        "> We stick to `matplotlib` to keep it lightweight and portable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(X.describe())\n",
        "\n",
        "# Histograms for each feature\n",
        "ax = X.hist(bins=15, figsize=(10,6))\n",
        "plt.suptitle(\"Feature Distributions\", y=1.02)\n",
        "plt.show()\n",
        "\n",
        "# Simple scatter: petal length vs petal width colored by species\n",
        "plt.figure(figsize=(6,4))\n",
        "for cls in np.unique(y):\n",
        "    mask = (y == cls)\n",
        "    plt.scatter(X.loc[mask, feature_names[2]], X.loc[mask, feature_names[3]], label=target_names[cls], alpha=0.8)\n",
        "plt.xlabel(feature_names[2])\n",
        "plt.ylabel(feature_names[3])\n",
        "plt.title(\"Petal length vs Petal width by species\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Train/Test Split\n",
        "We'll do a stratified split so that each class is represented proportionally in both training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "print(\"Train shape:\", X_train.shape, \" Test shape:\", X_test.shape)\n",
        "print(\"Train class counts:\\n\", y_train.value_counts().sort_index())\n",
        "print(\"Test class counts:\\n\", y_test.value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) (Optional) Feature Scaling\n",
        "Logistic Regression can benefit from scaling. We will standardize features using `StandardScaler`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled  = scaler.transform(X_test)\n",
        "X_train_scaled[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Train Logistic Regression\n",
        "- We use `multi_class='auto'` which picks OvR or multinomial depending on the solver.\n",
        "- `lbfgs` works well; we set `max_iter=1000` to avoid convergence warnings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "logreg = LogisticRegression(max_iter=1000, multi_class='auto', solver='lbfgs', random_state=42)\n",
        "logreg.fit(X_train_scaled, y_train)\n",
        "print(\"Training complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Evaluate on Test Set\n",
        "- Accuracy\n",
        "- Confusion Matrix\n",
        "- Classification Report (precision, recall, f1-score per class)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = logreg.predict(X_test_scaled)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
        "disp.plot(values_format='d')\n",
        "plt.title(\"Confusion Matrix (Test)\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Try Some Predictions\n",
        "We'll feed a couple of handmade samples to the trained model.\n",
        "\n",
        "Order of features:\n",
        "- sepal length (cm), sepal width (cm), petal length (cm), petal width (cm)\n",
        "\n",
        "Each row below is `[sepal length (cm), sepal width (cm), petal length (cm), petal width (cm)]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_new = np.array([\n",
        "    [5.1, 3.5, 1.4, 0.2],  # likely setosa\n",
        "    [6.0, 2.8, 4.5, 1.5],  # likely versicolor\n",
        "    [6.5, 3.0, 5.5, 2.0],  # likely virginica\n",
        "])\n",
        "X_new_scaled = scaler.transform(X_new)\n",
        "preds = logreg.predict(X_new_scaled)\n",
        "probs = logreg.predict_proba(X_new_scaled)\n",
        "for i, (p, pr) in enumerate(zip(preds, probs)):\n",
        "    print(f\"Sample {i}: predicted -> {target_names[p]} | probabilities -> {np.round(pr, 3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) (Optional) Save Model\n",
        "In case you want to persist the trained model and scaler for later use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "joblib.dump(logreg, \"logreg_iris.joblib\")\n",
        "joblib.dump(scaler, \"scaler_iris.joblib\")\n",
        "print(\"Saved: logreg_iris.joblib and scaler_iris.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Homework Ideas (for students)\n",
        "- Remove scaling and compare accuracy.\n",
        "- Change `test_size` (e.g., 0.3) \u2014 how does it affect performance?\n",
        "- Try `penalty='l1'` with solver `'liblinear'` and compare.\n",
        "- Plot decision boundaries for two features at a time.\n",
        "- Compute cross-validation accuracy using `cross_val_score`.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Iris_LogisticRegression_Colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}